---
output: html_document
editor_options: 
  chunk_output_type: console
---
## Text Cleaning & Wordclouds

### Libraries
```{r}
library(tm)
```


### Build corpus 

```{r}
dcfull <- read.csv('Dave Chapelle Comments.csv')

corpus <- iconv(dcfull$comment, to = "utf-8")
corpus <- Corpus(VectorSource(corpus))
inspect(corpus[1:5])
```
### Clean Text

```{r}
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, c('dave', 'chapelle', 'netflix', 'trans', 'walkout', 'really', 'well','get', 'hes', 'chappelle','just','like','people','thats','still','think','dont', 'can', 'one', "don't", "makes", "yeah", "cant", "doesnt","'re","didnt", "youre","isnt", "something", "someone", 'thing', 'also','got','anything','back','get','actually', 'things', 'theyre','many','take','though','trying','making','need','lot','pretty','sure'))

writeLines(as.character(corpus),"DC cleaned stop.txt")

```


### Document Term Matrix & Term Document Matrix

```{r}
ns_corpus <- tm_map(corpus, removeWords, stopwords('english'))
writeLines(as.character(ns_corpus),"DC cleaned nostop.txt")

tdm <- TermDocumentMatrix(ns_corpus)
tdm<- as.matrix(tdm)

# Bar Plot
w <- rowSums(tdm)
w <- subset(w, w>=200)
barplot(w, las = 2, col = rainbow(50))

library(wordcloud)
w <- sort(rowSums(tdm),decreasing = TRUE)
set.seed(222)
wordcloud(words = names(w),
          freq = w,
          max.words =150,
          random.order = F,
          min.freq = 150,
          colors = brewer.pal(8, 'Dark2'),
          scale = c(3,.1))


```

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


## Rinse and repeat for Joe Manchin Controversy

### Build corpus 

```{r}
jmfull <- read.csv('Joe Manchin Comments.csv')
# setwd('C:/Users/hzeig/Documents/Data Science/NYCDSA/projects/Reddit')
jcorpus <- iconv(jmfull$comment, to = "utf-8")
jcorpus <- Corpus(VectorSource(jcorpus))
inspect(jcorpus[1:5])
```
### Clean Text

```{r}
jcorpus <- tm_map(jcorpus, tolower)
jcorpus <- tm_map(jcorpus, removePunctuation)
jcorpus <- tm_map(jcorpus, removeNumbers)
jcorpus <- tm_map(jcorpus, stripWhitespace)
jcorpus <- tm_map(jcorpus, removeWords, c('joe', 'manchin','just','like','people','will','can','dont','also','isnt','really','still','doesnt','see','well','actually','just','like','people','thats','still','think','dont', 'can', 'one', "don't", "makes", "yeah", "cant", "doesnt","'re","didnt", "youre","isnt", "something", "someone", 'thing', 'also','got','anything','back','get','fuck'))

writeLines(as.character(corpus),"JM cleaned stop.txt")
```


### Document Term Matrix & Term Document Matrix

```{r}
ns_jcorpus <- tm_map(jcorpus, removeWords, stopwords('english'))
ns_jcorpus

writeLines(as.character(ns_jcorpus),"JM cleaned nostop.txt")

tdm <- TermDocumentMatrix(ns_jcorpus)
tdm<- as.matrix(tdm)

# Bar Plot
w <- rowSums(tdm)
w <- subset(w, w>=50)
barplot(w, las = 2, col = rainbow(50))

library(wordcloud)
w <- sort(rowSums(tdm),decreasing = TRUE)
set.seed(222)
wordcloud(words = names(w),
          freq = w,
          max.words =150,
          random.order = F,
          min.freq = 100,
          colors = brewer.pal(8, 'Dark2'),
          scale = c(3,.1))


```

