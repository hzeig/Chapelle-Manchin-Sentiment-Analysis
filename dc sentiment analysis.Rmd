---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Dave Chapelle Controversy Sentiment Analyses (EDA)

### Libraries:

```{r results=FALSE, message=FALSE, warning=FALSE}
library(sentimentr)
library(vader)
library(lubridate)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
library(tidyverse)
library(stringr)
library(stylo)

# rm(list=ls())
# setwd('C:/Users/hzeig/Documents/Data Science/NYCDSA/Projects/Reddit")
```

### Load and merge dataframes
```{r}
# import DFs
dc_comm <- read.csv("dccomments.csv")
dc_thre <- read.csv("dcthreads.csv")


# merge into one DF
dc_thre <- dc_thre %>% dplyr::select(subreddit, url, thread.author=author, 
                                     thread.date=date, title, 
                                     post=text, 
                                     thread.score=score, 
                                     thread.number.comments=comments)

dc_comm <- dc_comm %>% dplyr::select(url, comment.author=author, 
                                     comment.date=date, comment, 
                                     comment.score=score, comment_id)


dc_full <- merge(dc_thre, dc_comm)

```



### Quick stop-word removal

```{r}

library(tidytext)
view(stop_words)

dc_thre %>% delete.stop.words(title, 'is')


stopwords('en')

sapply(dc_full$thread.title, delete.stop.words)

dc_full$thread.title <- delete.stop.words(dc_full$thread.title, 'if')


dc_full$thread.title






```



### sentimentr 

```{r results=c(1,6)}
# 1. threads

# 1.1 by thread text
dc_sr_thre <- get_sentences(dc_thre$thread.text)
dc_sr_thre_sent <- sentiment_by(dc_sr_thre, dc_thre$thread.text)

# summary
summary(dc_sr_thre_sent)

# correlations
df1 <- merge(dc_sr_thre_sent, dc_thre)
cor(df1$thread.score, df1$thread.number.comments) # 0.781
cor(df1$ave_sentiment, df1$word_count) # -0.287
cor(df1$ave_sentiment, df1$thread.score) # 0.156
cor(df1$ave_sentiment, df1$thread.number.comments) # 0.057
## nothing fruitful

# 1.2 by thread title
dc_sr_titl <- get_sentences(dc_thre$thread.title)
dc_sr_titl_sent <- sentiment_by(dc_sr_titl, dc_thre$thread.title)

# summary
summary(dc_sr_titl_sent)

# correlations 
df12 <- merge(dc_sr_titl_sent, dc_thre)
cor(df12$ave_sentiment, df12$word_count)  ## -0.346**
cor(df12$ave_sentiment, df12$thread.score)  # 0.067
cor(df12$ave_sentiment, df12$thread.number.comments) # 0.05

# 1.3 comments

# by comment
dc_sr_comm <- get_sentences(dc_full$comment)
dc_sr_comm_sent <- sentiment_by(dc_sr_comm, dc_full$comment)


df13 <-merge(dc_sr_comm_sent, dc_full)
cor(df13$ave_sentiment, df13$word_count) # -0.018
cor(df13$ave_sentiment, df13$comment.score) # -0.006
cor(df13$ave_sentiment, df13$thread.number.comments) # 0.023
cor(df13$ave_sentiment, df13$thread.score) # 0.027


# summary
summary(dc_sr_comm_sent)

# plots
plot(density(dc_sr_titl_sent$ave_sentiment), 
     xlim=c(-1.5,1),
     ylim=c(0,4),
     main = "DC Average Sentiment by Text")
lines(density(dc_sr_thre_sent$ave_sentiment),
      col = 2)
lines(density(dc_sr_comm_sent$ave_sentiment),
      col = 3)
legend("topleft", 
       c('title text','post text','comments'),
       col = 1:3,
       lty = 1,
       title = "Text Colors")

```


```{r}
## 2. arranging by groups

# 2.1 by subreddit
# text
dc_sr_thre_sub <- get_sentences(dc_thre$thread.text)
dc_sr_thre_sub_sent <- sentiment_by(dc_sr_thre_sub, dc_thre$subreddit)

df13 <- merge(dc_sr_thre_sub, dc_thre)

df13 %>%
  group_by(subreddit) %>%
  mutate(subreddit = fct_reorder(subreddit, ave_sentiment)) %>%
  ggplot(aes(x=subreddit, y=ave_sentiment)) +
  geom_bar(stat='identity')


# title
dc_sr_titl_sub <- get_sentences(dc_thre$thread.title)
dc_sr_titl_sub_sent <- sentiment_by(dc_sr_titl_sub, dc_thre$subreddit)

df14 <- merge(dc_sr_titl, dc_thre)



# 2.2 by author


```


```{r}
# 3. Trends over time


```



### Valence Aware Dictionary and sEntiment Reasoner (VADER)

```{r}

# get vader sentiment data

dc_vd_titl <- dc_full %>% group_by(title) %>% vader_df(title)
dc_vd_thre <- dc_full %>% group_by(post) %>% vader_df(post)
dc_vd_comm <- dc_full %>% vader_df(comment)


# write into csv

saveRDS(dc_vd_titl, "dcvader.titles.rds", row.names = F)
saveRDS(dc_vd_thre, "dcvader.post.rds", row.names = F)
saveRDS(dc_vd_comm,"dcvader.comments.rds", row.names = F)


# read back into df

dc_vd_titl <- read_rds('dcvader.titles.rds')
dc_vd_post <- read_rds('dcvader.threads.rds')
dc_vd_comm <- read_rds('dcvader.comments.rds')


dc_vd_titl <- dc_vd_titl %>%  as_tibble()
dc_vd_post <- dc_vd_thre %>%  as_tibble()
dc_vd_comm <- dc_vd_comm %>%  as_tibble()


# narrow down necessary columns

dc_vd_titl <- dc_vd_titl %>%  select(title = text, 
                                     title.compound = compound,
                                     title.pos = pos,
                                     title.neu = neu,
                                     title.neg = neg)
dc_vd_post <- dc_vd_post %>%  select(post = text, 
                                     post.compound = compound,
                                     post.pos = pos,
                                     post.neu = neu,
                                     post.neg = neg)
dc_vd_comm <- dc_vd_comm %>%  select(commment = text, 
                                     comm.compound = compound,
                                     comm.pos = pos,
                                     comm.neu = neu,
                                     comm.neg = neg)

# merge into one big df with full df

vd_df <- merge(dc_full, dc_vd_titl)
vd_df <- merge(vd_df, dc_vd_post)
vd_df <- merge(vd_df, dc_vd_comm)

saveRDS(vd_df, "dcvaderfull.rds")


```