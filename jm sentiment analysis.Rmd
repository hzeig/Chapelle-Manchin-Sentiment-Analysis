---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Joe Manchin Controversy Sentiment Analyses (EDA)

### Libraries:

```{r results=FALSE, message=FALSE, warning=FALSE}
library(sentimentr)
library(vader)
library(lubridate)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
library(tidyverse)
library(stringr)

# rm(list=ls())

```

### Load and merge dataframes
```{r}
# import DFs
jm_comm <- read.csv("Joe Manchin Comments.csv")
jm_thre <- read.csv("Joe Manchin Threads.csv")


# merge into one DF
jm_thre <- jm_thre %>% dplyr::select(subreddit, url, thread.author=author, 
                                     thread.date=date, thread.title=title, 
                                     thread.text=text, 
                                     thread.score=score, 
                                     thread.number.comments=comments)

jm_comm <- jm_comm %>% dplyr::select(url, comment.author=author, 
                                     comment.date=date, comment, 
                                     comment.score=score, comment_id)


jm_full <- merge(jm_thre, jm_comm)

```


### sentimentr 

```{r results=c(1,6)}
# 1. threads

# 1.1 by thread text
jm_sr_thre <- get_sentences(jm_thre$thread.text)
jm_sr_thre <- sentiment_by(jm_sr_thre, jm_thre$thread.text)

# summary
summary(jm_sr_thre)

# correlations
df1 <- merge(jm_sr_thre, jm_thre)
cor(df1$thread.score, df1$thread.number.comments) # 0.853
cor(df1$ave_sentiment, df1$word_count) ## 0.345* <--- marginally high r^2
cor(df1$ave_sentiment, df1$thread.score) # -0.035
cor(df1$ave_sentiment, df1$thread.number.comments) # -0.042


# 1.2 by thread title
jm_sr_titl <- get_sentences(jm_thre$thread.title)
jm_sr_titl <- sentiment_by(jm_sr_titl, jm_thre$thread.title)

# summary
summary(jm_sr_titl)

# correlations 
df12 <- merge(jm_sr_titl, jm_thre)
cor(df12$ave_sentiment, df12$word_count)  ## 0.424* <--- marginally high r^2 
cor(df12$ave_sentiment, df12$thread.score)  # 0.051
cor(df12$ave_sentiment, df12$thread.number.comments) # 0.02

# 1.3 comments

# by comment
jm_sr_comm <- get_sentences(jm_full$comment)
jm_sr_comm <- sentiment_by(jm_sr_comm, jm_full$comment)


df13 <-merge(jm_sr_comm, jm_full)
cor(df13$ave_sentiment, df13$word_count) # 0.03
cor(df13$ave_sentiment, df13$comment.score) # -0.003
cor(df13$ave_sentiment, df13$thread.number.comments) # 0.015
cor(df13$ave_sentiment, df13$thread.score) # 0.009


# summary
summary(jm_sr_comm)

# plots
plot(density(jm_sr_titl$ave_sentiment), 
     xlim=c(-1.5,1.5),
     ylim=c(0,7),
     main = "Average Sentiment by Text", 
     xlab = "Average sentimentr Score")
lines(density(jm_sr_thre$ave_sentiment),
      col = 2)
lines(density(jm_sr_comm$ave_sentiment),
      col = 3)
legend("topleft", 
       c('title text','post text','comments'),
       col = 1:3,
       lty = 1,
       title = "Text Colors")

```


```{r}
## 2. arranging by groups

# 2.1 by subreddit
# text
jm_sr_thre_sub <- get_sentences(jm_thre$thread.text)
jm_sr_thre_sub <- sentiment_by(jm_sr_thre_sub, jm_thre$subreddit)

df13 <- merge(jm_sr_thre_sub, jm_thre)

df13 %>%
  group_by(subreddit) %>%
  mutate(subreddit = fct_reorder(subreddit, ave_sentiment)) %>%
  ggplot(aes(x=subreddit, y=ave_sentiment)) +
  geom_bar(stat='identity')


# title
jm_sr_titl_sub <- get_sentences(jm_thre$thread.title)
jm_sr_titl_sub <- sentiment_by(jm_sr_titl_sub, jm_thre$subreddit)

df14 <- merge(jm_sr_titl, jm_thre)



# 2.2 by author


```


```{r}
# 3. Trends over time


```



### Valence Aware Dictionary and sEntiment Reasoner (VADER)

```{r}
# jm_vd_thre <- vader_df(jm_thre$text)
# jm_vd_comm <- vader_df(jm_comm$comment)
# write.csv(jm_vd_thre, "jm vader thread sents.csv", row.names = F)
# write.csv(jm_vd_comm,"jm vader comment sents.csv", row.names = F)

jm_vd_thre <- read.csv('jm vader thread sents.csv')
jm_vd_comm <- read.csv('jm vader comment sents.csv')


# jm_sents <- rename(jm_vc_comm,comment = text)
# 
# head(jm_sents)
# jm_uv <- merge(jmfull,jm_sentsM)
# head(jm_uv)
# write.csv(jm_uv, "Vader Comment Data Merge.csv", row.names = F)
# 
# View(jm_uv)
# 
# cor(jm_uv)
# 

```


```{r}
# dsent <- jm_sents[,c(3:6)]
# 
# plot(dsent$pos, dsent$neg)
# # drops <- c("word_scores","but_count")
# # jm_sents1 <- jm_sents[ , !(names(jm_sents) %in% drops)]
# ```
# ```{r}
# # measuring for average length of comment
# 
# play <- jm_sents$text
# 
# play3 <- sapply(play, str_count)
# head(play3)
# 
# play2 <- strsplit(play, " ")
# 
# wl <- sapply(play2, length)
# 
# mean(wl)
# summary(wl)
# 
# plot(density(wl))
# 
# library(MASS)
# ```
# 
# 
# ```{r}
# dsent1 <- pivot_longer(dsent, c(1:4), 
#                        names_to = "type", 
#                        values_to = "valence", 
#                        values_drop_na = TRUE)
# 
# dmeans <- dsent1 %>% 
#   group_by(type) %>% 
#   summarise(avg_valence = mean(valence))
# 
# dtype <- dsent1 %>% group_by(type)
# 
# barplot(dmeans$avg_valence)
# boxplot(dtype$valence ~ dtype$type)
# 
# dtype

```

### upvote analysis

```{r}



```

## Joe Manchin analysis

```{r}


jmfull <- read.csv("Joe Manchin Comments.csv")
jmfull$comment[1:5]
jm_sents <- vader_df(jmfull$comment)
View(jm_sents)
write.csv(jm_sents,"JM vader sents.csv", row.names = F)
jm_sents <- read.csv('JM vader sents.csv')

str(jm_sents)

jsent <- jm_sents[,c(3:6)]


# drops <- c("word_scores","but_count")
# jm_sents1 <- jm_sents[ , !(names(jm_sents) %in% drops)]



jsent1 <- pivot_longer(jsent, c(1:4), names_to = "type", values_to = "valence", values_drop_na = TRUE)

jmeans <- jsent1 %>% 
  group_by(type) %>% 
  summarise(avg_valence = mean(valence))

?barplot

barplot(jmeans$avg_valence)
jsent_type <- jsent1 %>% group_by(type)

boxplot(jsent_type, xlab='measure', ylab='valence', ann=T)


```

